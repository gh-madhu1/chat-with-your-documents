# App Information
APP_TITLE=Chat With Your Docs
APP_VERSION=0.1.0

# Local LLM Configuration
USE_LOCAL_LLM=true
LOCAL_LLM_MODEL=Qwen/Qwen2.5-1.5B-Instruct
LOCAL_LLM_DEVICE=auto
LOCAL_LLM_MAX_LENGTH=4096
LOCAL_LLM_TEMPERATURE=0.1
LOCAL_LLM_TOP_P=0.9
LOCAL_LLM_TOP_K=25
LOCAL_LLM_REPETITION_PENALTY=1.1

# Prompt Settings
SYSTEM_PROMPT="You are an enterprise AI assistant designed to answer questions using retrieved document content. Prioritize factual accuracy, reference relevant context when possible, and maintain a clear, structured response. If the answer cannot be derived from the documents, explicitly state the limitation."

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu
EMBEDDING_BATCH_SIZE=32
EMBEDDING_DIMENSION=384

# Vector Database - Milvus Lite (in-memory)
MILVUS_DB_PATH=./data/milvus_lite.db
MILVUS_COLLECTION_NAME=documents

# File Storage
FILE_STORAGE_DIR=./data/files

# Document Processing
UPLOAD_DIR=./data/uploads
MAX_FILE_SIZE_MB=50
ALLOWED_EXTENSIONS=.pdf,.txt,.md

# Chunking Strategy
CHUNKING_STRATEGY=recursive
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Retrieval
TOP_K_RETRIEVAL=5
SIMILARITY_THRESHOLD=0.7
USE_RERANKING=true

# Conversation
MAX_CONVERSATION_HISTORY=10
SESSION_TIMEOUT_MINUTES=30

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Evaluation
RAGAS_METRICS=faithfulness,answer_relevance,context_relevance,answer_correctness
